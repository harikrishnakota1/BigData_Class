{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOMEWORK 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.1 To Create a crawler using the webcrawler provided, have it crawl the first 200 pages from a base URL of your choosing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below are the steps to create the crawler, that I followed from my lecture https://github.com/pschragger/big-data-python-class/blob/master/Lectures/Lecture_7_-_Link_Analysis.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scrapy \n",
    "import os\n",
    "os.chdir(\"C:\\\\Users\\\\Pavani\\\\Desktop\\\\bigdata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file code already exists.\n"
     ]
    }
   ],
   "source": [
    "mkdir code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pavani\\Desktop\\bigdata\\code\n"
     ]
    }
   ],
   "source": [
    "cd code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Windows [Version 10.0.15063]\r\n",
      "(c) 2017 Microsoft Corporation. All rights reserved.\r\n",
      "\r\n",
      "C:\\Users\\Pavani\\Desktop\\bigdata\\code>scrapy startproject tutorial\n",
      "Error: scrapy.cfg already exists in C:\\Users\\Pavani\\Desktop\\bigdata\\code\\tutorial\r\n",
      "\r\n",
      "C:\\Users\\Pavani\\Desktop\\bigdata\\code>"
     ]
    }
   ],
   "source": [
    "%%cmd\n",
    "scrapy startproject tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pavani\\Desktop\\bigdata\\code\\tutorial\n"
     ]
    }
   ],
   "source": [
    "cd tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Windows [Version 10.0.15063]\r\n",
      "(c) 2017 Microsoft Corporation. All rights reserved.\r\n",
      "\r\n",
      "C:\\Users\\Pavani\\Desktop\\bigdata\\code\\tutorial>scrapy genspider weather weather.com\n",
      "Spider 'weather' already exists in module:\r\n",
      "  tutorial.spiders.weather\r\n",
      "\r\n",
      "C:\\Users\\Pavani\\Desktop\\bigdata\\code\\tutorial>"
     ]
    }
   ],
   "source": [
    "%%cmd\n",
    "scrapy genspider weather weather.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pavani\\Desktop\\bigdata\\code\\tutorial\\tutorial\n"
     ]
    }
   ],
   "source": [
    "cd tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pavani\\Desktop\\bigdata\\code\\tutorial\\tutorial\\spiders\n"
     ]
    }
   ],
   "source": [
    "cd spiders/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting weather.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile weather.py\n",
    "import scrapy\n",
    "\n",
    "class WeatherItem(scrapy.Item):\n",
    "    title = scrapy.Field()\n",
    "    link = scrapy.Field()\n",
    "    resp = scrapy.Field()\n",
    "    \n",
    "class WeatherSpider(scrapy.Spider):\n",
    "    name = 'weather'\n",
    "    allowed_domains = ['weather.com']\n",
    "    start_urls = ['https://weather.com/']\n",
    "\n",
    "    def parse(self, response):\n",
    "        hxs = scrapy.Selector(response)\n",
    "        titles = hxs.xpath('//ul/li')\n",
    "        item = []\n",
    "        for title in titles:\n",
    "            obj = WeatherItem()\n",
    "            obj[\"title\"] = title.xpath(\"a/text()\").extract()\n",
    "            obj[\"link\"] = title.xpath(\"a/@href\").extract()\n",
    "            obj[\"resp\"] = response\n",
    "            if obj[\"title\"] != []:\n",
    "                item.append(obj)\n",
    "\n",
    "        return item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following command saves the crawled urls in weather_txt.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Windows [Version 10.0.15063]\r\n",
      "(c) 2017 Microsoft Corporation. All rights reserved.\r\n",
      "\r\n",
      "C:\\Users\\Pavani\\Desktop\\bigdata\\code\\tutorial\\tutorial\\spiders>scrapy crawl weather -o weather_txt.csv -t csv\n",
      "\r\n",
      "C:\\Users\\Pavani\\Desktop\\bigdata\\code\\tutorial\\tutorial\\spiders>"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-11-19 01:57:26 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: tutorial)\r\n",
      "2017-11-19 01:57:26 [scrapy.utils.log] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'tutorial.spiders', 'FEED_URI': 'weather_txt.csv', 'SPIDER_MODULES': ['tutorial.spiders'], 'BOT_NAME': 'tutorial', 'ROBOTSTXT_OBEY': True, 'FEED_FORMAT': 'csv'}\r\n",
      "2017-11-19 01:57:26 [scrapy.middleware] INFO: Enabled extensions:\r\n",
      "['scrapy.extensions.feedexport.FeedExporter',\r\n",
      " 'scrapy.extensions.logstats.LogStats',\r\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\r\n",
      " 'scrapy.extensions.corestats.CoreStats']\r\n",
      "2017-11-19 01:57:26 [scrapy.middleware] INFO: Enabled downloader middlewares:\r\n",
      "['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',\r\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\r\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\r\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\r\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\r\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\r\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\r\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\r\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\r\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\r\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\r\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\r\n",
      "2017-11-19 01:57:26 [scrapy.middleware] INFO: Enabled spider middlewares:\r\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\r\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\r\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\r\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\r\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\r\n",
      "2017-11-19 01:57:26 [scrapy.middleware] INFO: Enabled item pipelines:\r\n",
      "[]\r\n",
      "2017-11-19 01:57:26 [scrapy.core.engine] INFO: Spider opened\r\n",
      "2017-11-19 01:57:26 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method ?.open_spider of <scrapy.extensions.feedexport.FeedExporter object at 0x0000000005367470>>\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\twisted\\internet\\defer.py\", line 150, in maybeDeferred\r\n",
      "    result = f(*args, **kw)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\r\n",
      "    return receiver(*arguments, **named)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\scrapy\\extensions\\feedexport.py\", line 192, in open_spider\r\n",
      "    file = storage.open(spider)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\scrapy\\extensions\\feedexport.py\", line 88, in open\r\n",
      "    return open(self.path, 'ab')\r\n",
      "IOError: [Errno 13] Permission denied: 'weather_txt.csv'\r\n",
      "2017-11-19 01:57:26 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\r\n",
      "2017-11-19 01:57:26 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023\r\n",
      "2017-11-19 01:57:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://weather.com/robots.txt> (referer: None)\r\n",
      "2017-11-19 01:57:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://weather.com/> (referer: None)\r\n",
      "2017-11-19 01:57:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://weather.com/>\r",
      "\r\n",
      "{'link': [u'/weather/today/l/USDC0001:1:US'],\r\n",
      " 'resp': <200 https://weather.com/>,\r\n",
      " 'title': [u\"Today's Forecast\"]}\r\n",
      "2017-11-19 01:57:26 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method ?.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000000005367470>>\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\twisted\\internet\\defer.py\", line 150, in maybeDeferred\r\n",
      "    result = f(*args, **kw)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\r\n",
      "    return receiver(*arguments, **named)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\scrapy\\extensions\\feedexport.py\", line 220, in item_scraped\r\n",
      "    slot = self.slot\r\n",
      "AttributeError: 'FeedExporter' object has no attribute 'slot'\r\n",
      "2017-11-19 01:57:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://weather.com/>\r",
      "\r\n",
      "{'link': [u'/weather/hourbyhour/l/USDC0001:1:US'],\r\n",
      " 'resp': <200 https://weather.com/>,\r\n",
      " 'title': [u'Hourly Forecast']}\r\n",
      "2017-11-19 01:57:26 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method ?.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000000005367470>>\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\twisted\\internet\\defer.py\", line 150, in maybeDeferred\r\n",
      "    result = f(*args, **kw)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\r\n",
      "    return receiver(*arguments, **named)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\scrapy\\extensions\\feedexport.py\", line 220, in item_scraped\r\n",
      "    slot = self.slot\r\n",
      "AttributeError: 'FeedExporter' object has no attribute 'slot'\r\n",
      "2017-11-19 01:57:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://weather.com/>\r",
      "\r\n",
      "{'link': [u'/weather/tenday/l/USDC0001:1:US'],\r\n",
      " 'resp': <200 https://weather.com/>,\r\n",
      " 'title': [u'10 Day Forecast']}\r\n",
      "2017-11-19 01:57:26 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method ?.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000000005367470>>\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\twisted\\internet\\defer.py\", line 150, in maybeDeferred\r\n",
      "    result = f(*args, **kw)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\r\n",
      "    return receiver(*arguments, **named)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\scrapy\\extensions\\feedexport.py\", line 220, in item_scraped\r\n",
      "    slot = self.slot\r\n",
      "AttributeError: 'FeedExporter' object has no attribute 'slot'\r\n",
      "2017-11-19 01:57:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://weather.com/>\r",
      "\r\n",
      "{'link': [u'/forecast/news/national-forecast-20141009'],\r\n",
      " 'resp': <200 https://weather.com/>,\r\n",
      " 'title': [u'National Forecast']}\r\n",
      "2017-11-19 01:57:26 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method ?.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000000005367470>>\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\twisted\\internet\\defer.py\", line 150, in maybeDeferred\r\n",
      "    result = f(*args, **kw)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\r\n",
      "    return receiver(*arguments, **named)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\scrapy\\extensions\\feedexport.py\", line 220, in item_scraped\r\n",
      "    slot = self.slot\r\n",
      "AttributeError: 'FeedExporter' object has no attribute 'slot'\r\n",
      "2017-11-19 01:57:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://weather.com/>\r",
      "\r\n",
      "{'link': [u'/life/manage-notifications'],\r\n",
      " 'resp': <200 https://weather.com/>,\r\n",
      " 'title': [u'Get Notifications']}\r\n",
      "2017-11-19 01:57:26 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method ?.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000000005367470>>\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\twisted\\internet\\defer.py\", line 150, in maybeDeferred\r\n",
      "    result = f(*args, **kw)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\r\n",
      "    return receiver(*arguments, **named)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\scrapy\\extensions\\feedexport.py\", line 220, in item_scraped\r\n",
      "    slot = self.slot\r\n",
      "AttributeError: 'FeedExporter' object has no attribute 'slot'\r\n",
      "2017-11-19 01:57:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://weather.com/>\r",
      "\r\n",
      "{'link': [u'/weather/radar/interactive/l/USDC0001:1:US?animation=true'],\r\n",
      " 'resp': <200 https://weather.com/>,\r\n",
      " 'title': [u'Weather in Motion\\xae']}\r\n",
      "2017-11-19 01:57:26 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method ?.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000000005367470>>\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\twisted\\internet\\defer.py\", line 150, in maybeDeferred\r\n",
      "    result = f(*args, **kw)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\r\n",
      "    return receiver(*arguments, **named)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\scrapy\\extensions\\feedexport.py\", line 220, in item_scraped\r\n",
      "    slot = self.slot\r\n",
      "AttributeError: 'FeedExporter' object has no attribute 'slot'\r\n",
      "2017-11-19 01:57:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://weather.com/>\r",
      "\r\n",
      "{'link': [u'/weather/radar/interactive/l/USDC0001:1:US'],\r\n",
      " 'resp': <200 https://weather.com/>,\r\n",
      " 'title': [u'Radar Maps']}\r\n",
      "2017-11-19 01:57:26 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method ?.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000000005367470>>\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\twisted\\internet\\defer.py\", line 150, in maybeDeferred\r\n",
      "    result = f(*args, **kw)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\r\n",
      "    return receiver(*arguments, **named)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\scrapy\\extensions\\feedexport.py\", line 220, in item_scraped\r\n",
      "    slot = self.slot\r\n",
      "AttributeError: 'FeedExporter' object has no attribute 'slot'\r\n",
      "2017-11-19 01:57:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://weather.com/>\r",
      "\r\n",
      "{'link': [u'/maps/currentusweather'],\r\n",
      " 'resp': <200 https://weather.com/>,\r\n",
      " 'title': [u'Classic Weather Maps']}\r\n",
      "2017-11-19 01:57:26 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method ?.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000000005367470>>\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\twisted\\internet\\defer.py\", line 150, in maybeDeferred\r\n",
      "    result = f(*args, **kw)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\r\n",
      "    return receiver(*arguments, **named)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\scrapy\\extensions\\feedexport.py\", line 220, in item_scraped\r\n",
      "    slot = self.slot\r\n",
      "AttributeError: 'FeedExporter' object has no attribute 'slot'\r\n",
      "2017-11-19 01:57:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://weather.com/>\r",
      "\r\n",
      "{'link': [u'/weather/radar/interactive/l/USDC0001:1:US?layers=sat&zoom=3'],\r\n",
      " 'resp': <200 https://weather.com/>,\r\n",
      " 'title': [u'Regional Satellite']}\r\n",
      "2017-11-19 01:57:26 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method ?.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000000005367470>>\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\twisted\\internet\\defer.py\", line 150, in maybeDeferred\r\n",
      "    result = f(*args, **kw)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\r\n",
      "    return receiver(*arguments, **named)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\scrapy\\extensions\\feedexport.py\", line 220, in item_scraped\r\n",
      "    slot = self.slot\r\n",
      "AttributeError: 'FeedExporter' object has no attribute 'slot'\r\n",
      "2017-11-19 01:57:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://weather.com/>\r",
      "\r\n",
      "{'link': [u'/weather/radar/interactive/l/USDC0001:1:US?layers=rwi'],\r\n",
      " 'resp': <200 https://weather.com/>,\r\n",
      " 'title': [u'Driving Difficulty Map']}\r\n",
      "2017-11-19 01:57:26 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method ?.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000000005367470>>\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\twisted\\internet\\defer.py\", line 150, in maybeDeferred\r\n",
      "    result = f(*args, **kw)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\r\n",
      "    return receiver(*arguments, **named)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\scrapy\\extensions\\feedexport.py\", line 220, in item_scraped\r\n",
      "    slot = self.slot\r\n",
      "AttributeError: 'FeedExporter' object has no attribute 'slot'\r\n",
      "2017-11-19 01:57:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://weather.com/>\r",
      "\r\n",
      "{'link': [u'/weather/radar/interactive/l/USDC0001:1:US?overlays=currtrafficspeed&zoom=9'],\r\n",
      " 'resp': <200 https://weather.com/>,\r\n",
      " 'title': [u'Traffic and Radar NEW!']}\r\n",
      "2017-11-19 01:57:26 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method ?.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000000005367470>>\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\twisted\\internet\\defer.py\", line 150, in maybeDeferred\r\n",
      "    result = f(*args, **kw)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\r\n",
      "    return receiver(*arguments, **named)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\scrapy\\extensions\\feedexport.py\", line 220, in item_scraped\r\n",
      "    slot = self.slot\r\n",
      "AttributeError: 'FeedExporter' object has no attribute 'slot'\r\n",
      "2017-11-19 01:57:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://weather.com/>\r",
      "\r\n",
      "{'link': [u'/maps/severealerts'],\r\n",
      " 'resp': <200 https://weather.com/>,\r\n",
      " 'title': [u'Severe Alerts']}\r\n",
      "2017-11-19 01:57:26 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method ?.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000000005367470>>\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\twisted\\internet\\defer.py\", line 150, in maybeDeferred\r\n",
      "    result = f(*args, **kw)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\r\n",
      "    return receiver(*arguments, **named)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\scrapy\\extensions\\feedexport.py\", line 220, in item_scraped\r\n",
      "    slot = self.slot\r\n",
      "AttributeError: 'FeedExporter' object has no attribute 'slot'\r\n",
      "2017-11-19 01:57:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://weather.com/>\r",
      "\r\n",
      "{'link': [u'/storms/hurricane-central'],\r\n",
      " 'resp': <200 https://weather.com/>,\r\n",
      " 'title': [u'Hurricane Central']}\r\n",
      "2017-11-19 01:57:26 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method ?.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000000005367470>>\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\twisted\\internet\\defer.py\", line 150, in maybeDeferred\r\n",
      "    result = f(*args, **kw)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\r\n",
      "    return receiver(*arguments, **named)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\scrapy\\extensions\\feedexport.py\", line 220, in item_scraped\r\n",
      "    slot = self.slot\r\n",
      "AttributeError: 'FeedExporter' object has no attribute 'slot'\r\n",
      "2017-11-19 01:57:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://weather.com/>\r",
      "\r\n",
      "{'link': [u'/storms/tornado-central'],\r\n",
      " 'resp': <200 https://weather.com/>,\r\n",
      " 'title': [u'Tornado Central']}\r\n",
      "2017-11-19 01:57:26 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method ?.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000000005367470>>\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\twisted\\internet\\defer.py\", line 150, in maybeDeferred\r\n",
      "    result = f(*args, **kw)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\r\n",
      "    return receiver(*arguments, **named)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\scrapy\\extensions\\feedexport.py\", line 220, in item_scraped\r\n",
      "    slot = self.slot\r\n",
      "AttributeError: 'FeedExporter' object has no attribute 'slot'\r\n",
      "2017-11-19 01:57:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://weather.com/>\r",
      "\r\n",
      "{'link': [u'/storms/tornado/forecast/local/l/USDC0001:1:US'],\r\n",
      " 'resp': <200 https://weather.com/>,\r\n",
      " 'title': [u'Local Severe Storm Risk']}\r\n",
      "2017-11-19 01:57:26 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method ?.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000000005367470>>\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\twisted\\internet\\defer.py\", line 150, in maybeDeferred\r\n",
      "    result = f(*args, **kw)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\r\n",
      "    return receiver(*arguments, **named)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\scrapy\\extensions\\feedexport.py\", line 220, in item_scraped\r\n",
      "    slot = self.slot\r\n",
      "AttributeError: 'FeedExporter' object has no attribute 'slot'\r\n",
      "2017-11-19 01:57:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://weather.com/>\r",
      "\r\n",
      "{'link': [u'/storms/winter-central'],\r\n",
      " 'resp': <200 https://weather.com/>,\r\n",
      " 'title': [u'Winter Storm Central']}\r\n",
      "2017-11-19 01:57:26 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method ?.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000000005367470>>\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\twisted\\internet\\defer.py\", line 150, in maybeDeferred\r\n",
      "    result = f(*args, **kw)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\r\n",
      "    return receiver(*arguments, **named)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\scrapy\\extensions\\feedexport.py\", line 220, in item_scraped\r\n",
      "    slot = self.slot\r\n",
      "AttributeError: 'FeedExporter' object has no attribute 'slot'\r\n",
      "2017-11-19 01:57:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://weather.com/>\r",
      "\r\n",
      "{'link': [u'/tv/shows/responding-by-storm'],\r\n",
      " 'resp': <200 https://weather.com/>,\r\n",
      " 'title': [u'Responding by Storm']}\r\n",
      "2017-11-19 01:57:26 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method ?.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000000005367470>>\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\twisted\\internet\\defer.py\", line 150, in maybeDeferred\r\n",
      "    result = f(*args, **kw)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\r\n",
      "    return receiver(*arguments, **named)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\scrapy\\extensions\\feedexport.py\", line 220, in item_scraped\r\n",
      "    slot = self.slot\r\n",
      "AttributeError: 'FeedExporter' object has no attribute 'slot'\r\n",
      "2017-11-19 01:57:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://weather.com/>\r",
      "\r\n",
      "{'link': [u'/safety'],\r\n",
      " 'resp': <200 https://weather.com/>,\r\n",
      " 'title': [u'Safety and Preparedness ']}\r\n",
      "2017-11-19 01:57:27 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method ?.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000000005367470>>\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\twisted\\internet\\defer.py\", line 150, in maybeDeferred\r\n",
      "    result = f(*args, **kw)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\r\n",
      "    return receiver(*arguments, **named)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\scrapy\\extensions\\feedexport.py\", line 220, in item_scraped\r\n",
      "    slot = self.slot\r\n",
      "AttributeError: 'FeedExporter' object has no attribute 'slot'\r\n",
      "2017-11-19 01:57:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://weather.com/>\r",
      "\r\n",
      "{'link': [u'/storms/report-recover'],\r\n",
      " 'resp': <200 https://weather.com/>,\r\n",
      " 'title': [u'Report and Recover']}\r\n",
      "2017-11-19 01:57:27 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method ?.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000000005367470>>\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\twisted\\internet\\defer.py\", line 150, in maybeDeferred\r\n",
      "    result = f(*args, **kw)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\r\n",
      "    return receiver(*arguments, **named)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\scrapy\\extensions\\feedexport.py\", line 220, in item_scraped\r\n",
      "    slot = self.slot\r\n",
      "AttributeError: 'FeedExporter' object has no attribute 'slot'\r\n",
      "2017-11-19 01:57:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://weather.com/>\r",
      "\r\n",
      "{'link': [u'/life/manage-notifications'],\r\n",
      " 'resp': <200 https://weather.com/>,\r\n",
      " 'title': [u'Get Severe Alerts']}\r\n",
      "2017-11-19 01:57:27 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method ?.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000000005367470>>\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\twisted\\internet\\defer.py\", line 150, in maybeDeferred\r\n",
      "    result = f(*args, **kw)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\r\n",
      "    return receiver(*arguments, **named)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\scrapy\\extensions\\feedexport.py\", line 220, in item_scraped\r\n",
      "    slot = self.slot\r\n",
      "AttributeError: 'FeedExporter' object has no attribute 'slot'\r\n",
      "2017-11-19 01:57:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://weather.com/>\r",
      "\r\n",
      "{'link': [u'/news/trending/video/divers-free-huge-sharks-caught-in-net'],\r\n",
      " 'resp': <200 https://weather.com/>,\r\n",
      " 'title': [u'Top Stories']}\r\n",
      "2017-11-19 01:57:27 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method ?.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000000005367470>>\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\twisted\\internet\\defer.py\", line 150, in maybeDeferred\r\n",
      "    result = f(*args, **kw)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\r\n",
      "    return receiver(*arguments, **named)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\scrapy\\extensions\\feedexport.py\", line 220, in item_scraped\r\n",
      "    slot = self.slot\r\n",
      "AttributeError: 'FeedExporter' object has no attribute 'slot'\r\n",
      "2017-11-19 01:57:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://weather.com/>\r",
      "\r\n",
      "{'link': [u'/news/trending/video/divers-free-huge-sharks-caught-in-net'],\r\n",
      " 'resp': <200 https://weather.com/>,\r\n",
      " 'title': [u'Video']}\r\n",
      "2017-11-19 01:57:27 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method ?.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000000005367470>>\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\twisted\\internet\\defer.py\", line 150, in maybeDeferred\r\n",
      "    result = f(*args, **kw)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\r\n",
      "    return receiver(*arguments, **named)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\scrapy\\extensions\\feedexport.py\", line 220, in item_scraped\r\n",
      "    slot = self.slot\r\n",
      "AttributeError: 'FeedExporter' object has no attribute 'slot'\r\n",
      "2017-11-19 01:57:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://weather.com/>\r",
      "\r\n",
      "{'link': [u'/series/crazimals'],\r\n",
      " 'resp': <200 https://weather.com/>,\r\n",
      " 'title': [u'Crazimals']}\r\n",
      "2017-11-19 01:57:27 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method ?.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000000005367470>>\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\twisted\\internet\\defer.py\", line 150, in maybeDeferred\r\n",
      "    result = f(*args, **kw)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\r\n",
      "    return receiver(*arguments, **named)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\scrapy\\extensions\\feedexport.py\", line 220, in item_scraped\r\n",
      "    slot = self.slot\r\n",
      "AttributeError: 'FeedExporter' object has no attribute 'slot'\r\n",
      "2017-11-19 01:57:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://weather.com/>\r",
      "\r\n",
      "{'link': [u'/news'], 'resp': <200 https://weather.com/>, 'title': [u'News']}\r\n",
      "2017-11-19 01:57:27 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method ?.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000000005367470>>\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\twisted\\internet\\defer.py\", line 150, in maybeDeferred\r\n",
      "    result = f(*args, **kw)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\r\n",
      "    return receiver(*arguments, **named)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\scrapy\\extensions\\feedexport.py\", line 220, in item_scraped\r\n",
      "    slot = self.slot\r\n",
      "AttributeError: 'FeedExporter' object has no attribute 'slot'\r\n",
      "2017-11-19 01:57:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://weather.com/>\r",
      "\r\n",
      "{'link': [u'/photos/contest'],\r\n",
      " 'resp': <200 https://weather.com/>,\r\n",
      " 'title': [u'2017 Photo Contest']}\r\n",
      "2017-11-19 01:57:27 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method ?.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000000005367470>>\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\twisted\\internet\\defer.py\", line 150, in maybeDeferred\r\n",
      "    result = f(*args, **kw)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\r\n",
      "    return receiver(*arguments, **named)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\scrapy\\extensions\\feedexport.py\", line 220, in item_scraped\r\n",
      "    slot = self.slot\r\n",
      "AttributeError: 'FeedExporter' object has no attribute 'slot'\r\n",
      "2017-11-19 01:57:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://weather.com/>\r",
      "\r\n",
      "{'link': [u'/photos'],\r\n",
      " 'resp': <200 https://weather.com/>,\r\n",
      " 'title': [u'Fan Photos']}\r\n",
      "2017-11-19 01:57:27 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method ?.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000000005367470>>\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\twisted\\internet\\defer.py\", line 150, in maybeDeferred\r\n",
      "    result = f(*args, **kw)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\r\n",
      "    return receiver(*arguments, **named)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\scrapy\\extensions\\feedexport.py\", line 220, in item_scraped\r\n",
      "    slot = self.slot\r\n",
      "AttributeError: 'FeedExporter' object has no attribute 'slot'\r\n",
      "2017-11-19 01:57:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://weather.com/>\r",
      "\r\n",
      "{'link': [u'/slideshows'],\r\n",
      " 'resp': <200 https://weather.com/>,\r\n",
      " 'title': [u'Photos']}\r\n",
      "2017-11-19 01:57:27 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method ?.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000000005367470>>\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\twisted\\internet\\defer.py\", line 150, in maybeDeferred\r\n",
      "    result = f(*args, **kw)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\r\n",
      "    return receiver(*arguments, **named)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\scrapy\\extensions\\feedexport.py\", line 220, in item_scraped\r\n",
      "    slot = self.slot\r\n",
      "AttributeError: 'FeedExporter' object has no attribute 'slot'\r\n",
      "2017-11-19 01:57:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://weather.com/>\r",
      "\r\n",
      "{'link': [u'/photos/places/news/lets-go-places'],\r\n",
      " 'resp': <200 https://weather.com/>,\r\n",
      " 'title': [u\"Let's Go Places\"]}\r\n",
      "2017-11-19 01:57:27 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method ?.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000000005367470>>\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\twisted\\internet\\defer.py\", line 150, in maybeDeferred\r\n",
      "    result = f(*args, **kw)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\r\n",
      "    return receiver(*arguments, **named)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\scrapy\\extensions\\feedexport.py\", line 220, in item_scraped\r\n",
      "    slot = self.slot\r\n",
      "AttributeError: 'FeedExporter' object has no attribute 'slot'\r\n",
      "2017-11-19 01:57:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://weather.com/>\r",
      "\r\n",
      "{'link': [u'/forecast/boat-beach/l/USDC0001:1:US'],\r\n",
      " 'resp': <200 https://weather.com/>,\r\n",
      " 'title': [u'Boat & Beach Forecast']}\r\n",
      "2017-11-19 01:57:27 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method ?.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000000005367470>>\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\twisted\\internet\\defer.py\", line 150, in maybeDeferred\r\n",
      "    result = f(*args, **kw)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\r\n",
      "    return receiver(*arguments, **named)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\scrapy\\extensions\\feedexport.py\", line 220, in item_scraped\r\n",
      "    slot = self.slot\r\n",
      "AttributeError: 'FeedExporter' object has no attribute 'slot'\r\n",
      "2017-11-19 01:57:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://weather.com/>\r",
      "\r\n",
      "{'link': [u'/forecast/gorun/l/USDC0001:1:US'],\r\n",
      " 'resp': <200 https://weather.com/>,\r\n",
      " 'title': [u'Running Forecast']}\r\n",
      "2017-11-19 01:57:27 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method ?.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000000005367470>>\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\twisted\\internet\\defer.py\", line 150, in maybeDeferred\r\n",
      "    result = f(*args, **kw)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\r\n",
      "    return receiver(*arguments, **named)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\scrapy\\extensions\\feedexport.py\", line 220, in item_scraped\r\n",
      "    slot = self.slot\r\n",
      "AttributeError: 'FeedExporter' object has no attribute 'slot'\r\n",
      "2017-11-19 01:57:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://weather.com/>\r",
      "\r\n",
      "{'link': [u'/forecast/agriculture/l/USDC0001:1:US'],\r\n",
      " 'resp': <200 https://weather.com/>,\r\n",
      " 'title': [u'Farming Forecast']}\r\n",
      "2017-11-19 01:57:27 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method ?.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000000005367470>>\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\twisted\\internet\\defer.py\", line 150, in maybeDeferred\r\n",
      "    result = f(*args, **kw)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\r\n",
      "    return receiver(*arguments, **named)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\scrapy\\extensions\\feedexport.py\", line 220, in item_scraped\r\n",
      "    slot = self.slot\r\n",
      "AttributeError: 'FeedExporter' object has no attribute 'slot'\r\n",
      "2017-11-19 01:57:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://weather.com/>\r",
      "\r\n",
      "{'link': [u'/forecast/ski/l/USDC0001:1:US'],\r\n",
      " 'resp': <200 https://weather.com/>,\r\n",
      " 'title': [u'Ski Forecast']}\r\n",
      "2017-11-19 01:57:27 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method ?.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000000005367470>>\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\twisted\\internet\\defer.py\", line 150, in maybeDeferred\r\n",
      "    result = f(*args, **kw)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\r\n",
      "    return receiver(*arguments, **named)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\scrapy\\extensions\\feedexport.py\", line 220, in item_scraped\r\n",
      "    slot = self.slot\r\n",
      "AttributeError: 'FeedExporter' object has no attribute 'slot'\r\n",
      "2017-11-19 01:57:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://weather.com/>\r",
      "\r\n",
      "{'link': [u'/forecast/fishing/l/USDC0001:1:US'],\r\n",
      " 'resp': <200 https://weather.com/>,\r\n",
      " 'title': [u'Fishing Forecast']}\r\n",
      "2017-11-19 01:57:27 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method ?.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000000005367470>>\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\twisted\\internet\\defer.py\", line 150, in maybeDeferred\r\n",
      "    result = f(*args, **kw)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\r\n",
      "    return receiver(*arguments, **named)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\scrapy\\extensions\\feedexport.py\", line 220, in item_scraped\r\n",
      "    slot = self.slot\r\n",
      "AttributeError: 'FeedExporter' object has no attribute 'slot'\r\n",
      "2017-11-19 01:57:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://weather.com/>\r",
      "\r\n",
      "{'link': [u'/forecast/allergy/l/USDC0001:1:US'],\r\n",
      " 'resp': <200 https://weather.com/>,\r\n",
      " 'title': [u'Allergy Tracker']}\r\n",
      "2017-11-19 01:57:27 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method ?.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000000005367470>>\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\twisted\\internet\\defer.py\", line 150, in maybeDeferred\r\n",
      "    result = f(*args, **kw)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\r\n",
      "    return receiver(*arguments, **named)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\scrapy\\extensions\\feedexport.py\", line 220, in item_scraped\r\n",
      "    slot = self.slot\r\n",
      "AttributeError: 'FeedExporter' object has no attribute 'slot'\r\n",
      "2017-11-19 01:57:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://weather.com/>\r",
      "\r\n",
      "{'link': [u'/forecast/cold-flu/l/USDC0001:1:US'],\r\n",
      " 'resp': <200 https://weather.com/>,\r\n",
      " 'title': [u'Cold & Flu']}\r\n",
      "2017-11-19 01:57:27 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method ?.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000000005367470>>\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\twisted\\internet\\defer.py\", line 150, in maybeDeferred\r\n",
      "    result = f(*args, **kw)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\r\n",
      "    return receiver(*arguments, **named)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\scrapy\\extensions\\feedexport.py\", line 220, in item_scraped\r\n",
      "    slot = self.slot\r\n",
      "AttributeError: 'FeedExporter' object has no attribute 'slot'\r\n",
      "2017-11-19 01:57:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://weather.com/>\r",
      "\r\n",
      "{'link': [u'/tv/the-weather-channel-live/video/watch-the-weather-channel-live?pl=pl-live-tv-now'],\r\n",
      " 'resp': <200 https://weather.com/>,\r\n",
      " 'title': [u'Watch']}\r\n",
      "2017-11-19 01:57:27 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method ?.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000000005367470>>\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\twisted\\internet\\defer.py\", line 150, in maybeDeferred\r\n",
      "    result = f(*args, **kw)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\r\n",
      "    return receiver(*arguments, **named)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\scrapy\\extensions\\feedexport.py\", line 220, in item_scraped\r\n",
      "    slot = self.slot\r\n",
      "AttributeError: 'FeedExporter' object has no attribute 'slot'\r\n",
      "2017-11-19 01:57:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://weather.com/>\r",
      "\r\n",
      "{'link': [u'/tv'], 'resp': <200 https://weather.com/>, 'title': [u'Shows']}\r\n",
      "2017-11-19 01:57:27 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method ?.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000000005367470>>\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\twisted\\internet\\defer.py\", line 150, in maybeDeferred\r\n",
      "    result = f(*args, **kw)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\r\n",
      "    return receiver(*arguments, **named)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\scrapy\\extensions\\feedexport.py\", line 220, in item_scraped\r\n",
      "    slot = self.slot\r\n",
      "AttributeError: 'FeedExporter' object has no attribute 'slot'\r\n",
      "2017-11-19 01:57:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://weather.com/>\r",
      "\r\n",
      "{'link': [u'/tv/personalities'],\r\n",
      " 'resp': <200 https://weather.com/>,\r\n",
      " 'title': [u'Personalities']}\r\n",
      "2017-11-19 01:57:27 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method ?.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000000005367470>>\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\twisted\\internet\\defer.py\", line 150, in maybeDeferred\r\n",
      "    result = f(*args, **kw)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\r\n",
      "    return receiver(*arguments, **named)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\scrapy\\extensions\\feedexport.py\", line 220, in item_scraped\r\n",
      "    slot = self.slot\r\n",
      "AttributeError: 'FeedExporter' object has no attribute 'slot'\r\n",
      "2017-11-19 01:57:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://weather.com/>\r",
      "\r\n",
      "{'link': [u'//feedback.weather.com/customer/en/portal/articles'],\r\n",
      " 'resp': <200 https://weather.com/>,\r\n",
      " 'title': [u'Feedback']}\r\n",
      "2017-11-19 01:57:27 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method ?.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000000005367470>>\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\twisted\\internet\\defer.py\", line 150, in maybeDeferred\r\n",
      "    result = f(*args, **kw)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\r\n",
      "    return receiver(*arguments, **named)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\scrapy\\extensions\\feedexport.py\", line 220, in item_scraped\r\n",
      "    slot = self.slot\r\n",
      "AttributeError: 'FeedExporter' object has no attribute 'slot'\r\n",
      "2017-11-19 01:57:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://weather.com/>\r",
      "\r\n",
      "{'link': [u'http://ibm.biz/BdH3av'],\r\n",
      " 'resp': <200 https://weather.com/>,\r\n",
      " 'title': [u'Careers']}\r\n",
      "2017-11-19 01:57:27 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method ?.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000000005367470>>\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\twisted\\internet\\defer.py\", line 150, in maybeDeferred\r\n",
      "    result = f(*args, **kw)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\r\n",
      "    return receiver(*arguments, **named)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\scrapy\\extensions\\feedexport.py\", line 220, in item_scraped\r\n",
      "    slot = self.slot\r\n",
      "AttributeError: 'FeedExporter' object has no attribute 'slot'\r\n",
      "2017-11-19 01:57:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://weather.com/>\r",
      "\r\n",
      "{'link': [u'https://weather.com/apps'],\r\n",
      " 'resp': <200 https://weather.com/>,\r\n",
      " 'title': [u'Download Apps']}\r\n",
      "2017-11-19 01:57:27 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method ?.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000000005367470>>\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\twisted\\internet\\defer.py\", line 150, in maybeDeferred\r\n",
      "    result = f(*args, **kw)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\r\n",
      "    return receiver(*arguments, **named)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\scrapy\\extensions\\feedexport.py\", line 220, in item_scraped\r\n",
      "    slot = self.slot\r\n",
      "AttributeError: 'FeedExporter' object has no attribute 'slot'\r\n",
      "2017-11-19 01:57:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://weather.com/>\r",
      "\r\n",
      "{'link': [u'http://press.weather.com/'],\r\n",
      " 'resp': <200 https://weather.com/>,\r\n",
      " 'title': [u'Press Room']}\r\n",
      "2017-11-19 01:57:27 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method ?.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000000005367470>>\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\twisted\\internet\\defer.py\", line 150, in maybeDeferred\r\n",
      "    result = f(*args, **kw)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\r\n",
      "    return receiver(*arguments, **named)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\scrapy\\extensions\\feedexport.py\", line 220, in item_scraped\r\n",
      "    slot = self.slot\r\n",
      "AttributeError: 'FeedExporter' object has no attribute 'slot'\r\n",
      "2017-11-19 01:57:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://weather.com/>\r",
      "\r\n",
      "{'link': [u'http://advertising.weather.com/contact/'],\r\n",
      " 'resp': <200 https://weather.com/>,\r\n",
      " 'title': [u'Advertise With Us']}\r\n",
      "2017-11-19 01:57:27 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method ?.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000000005367470>>\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\twisted\\internet\\defer.py\", line 150, in maybeDeferred\r\n",
      "    result = f(*args, **kw)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\r\n",
      "    return receiver(*arguments, **named)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\scrapy\\extensions\\feedexport.py\", line 220, in item_scraped\r\n",
      "    slot = self.slot\r\n",
      "AttributeError: 'FeedExporter' object has no attribute 'slot'\r\n",
      "2017-11-19 01:57:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://weather.com/>\r",
      "\r\n",
      "{'link': [u'/life/local-advertise-self-serve'],\r\n",
      " 'resp': <200 https://weather.com/>,\r\n",
      " 'title': [u'Advertise- Self Service']}\r\n",
      "2017-11-19 01:57:27 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method ?.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000000005367470>>\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\twisted\\internet\\defer.py\", line 150, in maybeDeferred\r\n",
      "    result = f(*args, **kw)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\r\n",
      "    return receiver(*arguments, **named)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\scrapy\\extensions\\feedexport.py\", line 220, in item_scraped\r\n",
      "    slot = self.slot\r\n",
      "AttributeError: 'FeedExporter' object has no attribute 'slot'\r\n",
      "2017-11-19 01:57:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://weather.com/>\r",
      "\r\n",
      "{'link': [u'/tv'], 'resp': <200 https://weather.com/>, 'title': [u'TV']}\r\n",
      "2017-11-19 01:57:27 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method ?.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000000005367470>>\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\twisted\\internet\\defer.py\", line 150, in maybeDeferred\r\n",
      "    result = f(*args, **kw)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\r\n",
      "    return receiver(*arguments, **named)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\scrapy\\extensions\\feedexport.py\", line 220, in item_scraped\r\n",
      "    slot = self.slot\r\n",
      "AttributeError: 'FeedExporter' object has no attribute 'slot'\r\n",
      "2017-11-19 01:57:27 [scrapy.core.engine] INFO: Closing spider (finished)\r\n",
      "2017-11-19 01:57:27 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method ?.close_spider of <scrapy.extensions.feedexport.FeedExporter object at 0x0000000005367470>>\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\twisted\\internet\\defer.py\", line 150, in maybeDeferred\r\n",
      "    result = f(*args, **kw)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\r\n",
      "    return receiver(*arguments, **named)\r\n",
      "  File \"C:\\Users\\Pavani\\Anaconda2\\lib\\site-packages\\scrapy\\extensions\\feedexport.py\", line 201, in close_spider\r\n",
      "    slot = self.slot\r\n",
      "AttributeError: 'FeedExporter' object has no attribute 'slot'\r\n",
      "2017-11-19 01:57:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\r\n",
      "{'downloader/request_bytes': 783,\r\n",
      " 'downloader/request_count': 2,\r\n",
      " 'downloader/request_method_count/GET': 2,\r\n",
      " 'downloader/response_bytes': 58966,\r\n",
      " 'downloader/response_count': 2,\r\n",
      " 'downloader/response_status_count/200': 2,\r\n",
      " 'finish_reason': 'finished',\r\n",
      " 'finish_time': datetime.datetime(2017, 11, 19, 6, 57, 27, 24000),\r\n",
      " 'item_scraped_count': 45,\r\n",
      " 'log_count/DEBUG': 48,\r\n",
      " 'log_count/ERROR': 47,\r\n",
      " 'log_count/INFO': 7,\r\n",
      " 'response_received_count': 2,\r\n",
      " 'scheduler/dequeued': 1,\r\n",
      " 'scheduler/dequeued/memory': 1,\r\n",
      " 'scheduler/enqueued': 1,\r\n",
      " 'scheduler/enqueued/memory': 1,\r\n",
      " 'start_time': datetime.datetime(2017, 11, 19, 6, 57, 26, 552000)}\r\n",
      "2017-11-19 01:57:27 [scrapy.core.engine] INFO: Spider closed (finished)\r\n"
     ]
    }
   ],
   "source": [
    "%%cmd\n",
    "scrapy crawl weather -o weather_txt.csv -t csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.2 To create a Stochastic matrix from its resulting crawling as per https://cs7083.wordpress.com/2013/01/31/demystifying-the-pagerank-and-hits-algorithms/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "lst = []\n",
    "raw = pd.read_csv(\"weather_txt.csv\")\n",
    "raw['link'] = 'http://www.weather.com'+raw['link']\n",
    "r = raw['resp'][0]\n",
    "lst.append((r.split()[-1]).split('>')[-2])\n",
    "for i in range(len(raw)):\n",
    "    if raw['resp'][i] == r:\n",
    "        lst.append(raw['link'][i])\n",
    "    else:\n",
    "        r = raw['resp'][i]\n",
    "        lst.append((r.split()[-1]).split('>')[-2])\n",
    "        \n",
    "item = list(pd.DataFrame(lst)[0].unique())\n",
    "\n",
    "link = []\n",
    "length = len(lst)\n",
    "for i, val in enumerate(lst):\n",
    "    if i < length-1:\n",
    "        link.append((lst[i], lst[i+1]))\n",
    "\n",
    "n = pd.DataFrame(index=item, columns=item)\n",
    "m = n.replace(np.NaN, 0)\n",
    "for i in link:\n",
    "    m.loc[i] = 1.0\n",
    "\n",
    "ar = np.array(m)\n",
    "v = ar.sum(axis=1)\n",
    "\n",
    "result = ar/v[:, np.newaxis]\n",
    "matrix = np.nan_to_num(result)\n",
    "\n",
    "matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.3 Pass it through the Page Rank algorithm and provide the list of the top 5 page URLs in our sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "\n",
    "def pagerank(H):\n",
    "    n = len(H)\n",
    "    w = zeros(n)\n",
    "    rho = 1./n * ones(n);\n",
    "    for i in range(n):\n",
    "        if multiply.reduce(H[i]== zeros(n)):\n",
    "            w[i] = 1\n",
    "    newH = H + outer((1./n * w),ones(n))\n",
    " \n",
    "    theta=0.85\n",
    "    G = (theta * newH) + ((1-theta) * outer(1./n * ones(n), ones(n)))\n",
    "    #print rho\n",
    "    for j in range(10):\n",
    "        rho = dot(rho,G)\n",
    "        #print rho\n",
    "    \n",
    "    return list(rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[35, 36, 37, 38, 5]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#please create matrix again after interpreting pagerank algorithm\n",
    "r = pagerank(matrix)\n",
    "value = ((pd.DataFrame(r)).sort_values(0, ascending=False)).head(5)\n",
    "index = list(value.index)\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top five URLs:\n",
      "http://www.weather.com/tv\n",
      "http://www.weather.com/tv/personalities\n",
      "http://www.weather.com//feedback.weather.com/customer/en/portal/articles\n",
      "http://www.weather.comhttp://ibm.biz/BdH3av\n",
      "http://www.weather.com/life/manage-notifications\n"
     ]
    }
   ],
   "source": [
    "url = pd.DataFrame(item)\n",
    "print \"Top five URLs:\"\n",
    "for i in sort_index:\n",
    "    print url[0][i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.4 Using the hits algorithm ( with a connectivity matrix )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hits(A):\n",
    "    n= len(A)\n",
    "    Au= dot(transpose(A),A)\n",
    "    Hu = dot(A,transpose(A))\n",
    "    a = ones(n); h = ones(n)\n",
    "    #print a,h\n",
    "    for j in range(5):\n",
    "        a = dot(a,Au)\n",
    "        a= a/sum(a)\n",
    "        h = dot(h,Hu)\n",
    "        h = h/ sum(h)\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "value = pd.DataFrame(hits(ar))\n",
    "sort = (value.sort_values(0, ascending=False)).head(5)\n",
    "hit = list(sort.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 page URLs:\n",
      "http://www.weather.com/life/manage-notifications\n",
      "http://www.weather.com/news/trending/video/divers-free-huge-sharks-caught-in-net\n",
      "http://www.weather.com/life/local-advertise-self-serve\n",
      "http://www.weather.com/storms/report-recover\n",
      "http://www.weather.com/tv/the-weather-channel-live/video/watch-the-weather-channel-live?pl=pl-live-tv-now\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = pd.DataFrame(item)\n",
    "print \"Top 5 page URLs:\"\n",
    "for i in hit:\n",
    "    print 'http://www.weather.com'+(url[0][i]).split('.com')[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.5 Another ranking alogrithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tried to implement support vector machine for ranking but could not get it implemented on our webpage datasets. This is because I could not find training dataset to test my weather dataset.\n",
    "\n",
    "http://scikit-learn.org/stable/modules/svm.html                                         \n",
    "https://medium.com/machine-learning-101/chapter-2-svm-support-vector-machine-theory-f0812effc72\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://en.wikipedia.org/wiki/PageRank                                \n",
    "https://www.slideshare.net/Ankit007_/ranking-algorithms                         \n",
    "http://www.totallycommunications.com/latest/search-engine-basics-crawling-indexing-ranking/                       \n",
    "https://www.analyticsvidhya.com/blog/2017/09/understaing-support-vector-machine-example-code/                     \n",
    "https://cs7083.wordpress.com/2013/01/31/demystifying-the-pagerank-and-hits-algorithms/                                \n",
    "https://weather.com/                                                                                         \n",
    "https://doc.scrapy.org/en/latest/intro/tutorial.html                                                                  \n",
    "https://doc.scrapy.org/en/latest/intro/install.html#intro-install                                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
